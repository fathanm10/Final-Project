{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from train import train_model\n",
    "from dataset.utils import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88df472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "def redefine_train_parameters():\n",
    "    global device, epochs, learning_rate, loss_lr, num_classes, embedding_size\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    epochs = 20\n",
    "    learning_rate = 0.001\n",
    "    loss_lr = 0.01\n",
    "    num_classes = get_num_classes(train_dataset)\n",
    "    embedding_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed35c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, test_dataset, verbose=0, pretrained=True, save_path=None, model_name='resnet50', optimizer='adam', loss_func_name='proxy_anchor', use_loss_optimizer=False, drop_last=False):\n",
    "    train_loader = load_dataset(train_dataset, batch_size, shuffle=True, drop_last=drop_last)\n",
    "    test_loader = load_dataset(test_dataset, batch_size, shuffle=False, drop_last=drop_last)\n",
    "    model = train_model(model_name=model_name,\n",
    "                    loss_func_name=loss_func_name,\n",
    "                    num_classes=num_classes,\n",
    "                    dataloader=train_loader,\n",
    "                    optimizer=optimizer,\n",
    "                    embedding_size=embedding_size,\n",
    "                    epochs=epochs,\n",
    "                    learning_rate=learning_rate,\n",
    "                    verbose=verbose,\n",
    "                    use_loss_optimizer=use_loss_optimizer,\n",
    "                    save_path=save_path)\n",
    "    return model, train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfd647b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(dataset, k=10):\n",
    "    global r1,r2,r4,r8,r16,r32\n",
    "    np.random.shuffle(np.array(dataset))\n",
    "    k=k\n",
    "    split_len = len(dataset)//k\n",
    "    max_index = split_len*k\n",
    "    r1,r2,r4,r8,r16,r32= [],[],[],[],[],[]\n",
    "    for fold in range(k):\n",
    "        print(f'''----------\n",
    "fold {fold+1}:''')\n",
    "        start = split_len * fold\n",
    "        train_dataset = dataset[:start] + dataset[start + split_len:max_index]\n",
    "        test_dataset = dataset[start:start+split_len]\n",
    "        train_loader = load_dataset(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = load_dataset(test_dataset, batch_size, shuffle=False)\n",
    "        model = train_model(model_name='resnet50',\n",
    "                        loss_func_name='proxy_anchor',\n",
    "                        num_classes=num_classes,\n",
    "                        dataloader=train_loader,\n",
    "                        epochs=epochs,\n",
    "                        learning_rate=learning_rate,\n",
    "                        verbose=0)\n",
    "        recall = evaluate_cos(model, test_loader)\n",
    "        r1.append(recall[0])\n",
    "        r2.append(recall[1])\n",
    "        r4.append(recall[2])\n",
    "        r8.append(recall[3])\n",
    "        r16.append(recall[4])\n",
    "        r32.append(recall[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cba134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_recall(name, percent=False):\n",
    "    print(f'''Average Recall {name}:''')\n",
    "    \n",
    "    if percent:\n",
    "        print(f'''R@1 : {np.mean(r1)*100}\n",
    "R@2 : {np.mean(r2)*100}\n",
    "R@4 : {np.mean(r4)*100}\n",
    "R@8 : {np.mean(r8)*100}\n",
    "R@16 : {np.mean(r16)*100}\n",
    "R@32 : {np.mean(r32)*100}''')\n",
    "    \n",
    "    else:\n",
    "        print(f'''R@1 : {np.mean(r1)}\n",
    "R@2 : {np.mean(r2)}\n",
    "R@4 : {np.mean(r4)}\n",
    "R@8 : {np.mean(r8)}\n",
    "R@16 : {np.mean(r16)}\n",
    "R@32 : {np.mean(r32)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81dd549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(output, name):\n",
    "    try:\n",
    "        data = load_output()\n",
    "    except:\n",
    "        data = dict()\n",
    "    data[name] = output\n",
    "    with open('recall.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "        \n",
    "def load_output():\n",
    "    with open('recall.pkl', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b29f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=0, random_resized_crop=125, random=1, face_detection=False, unsharp=1, unsharp_amount=1, unsharp_radius=1)\n",
    "norm_mean,norm_std=normalize_dataset([train_dataset])\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=0, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, random_resized_crop=125, random=1, unsharp=1, unsharp_amount=1, unsharp_radius=1)\n",
    "test_dataset =  make_dataset('LFW', split='test',  image_size=0, crop=125, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, unsharp=1, unsharp_amount=1, unsharp_radius=1)\n",
    "redefine_train_parameters()\n",
    "name='PA+Unsharp'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')\n",
    "test_dataset = torchvision.datasets.LFWPairs(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.CenterCrop(125),\n",
    "        UnsharpFilter(radius=1,amount=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean,norm_std)\n",
    "    ])\n",
    ")\n",
    "labels,sim_scores = evaluate(model,test_dataset)\n",
    "visualize(labels,sim_scores)\n",
    "\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=0, random_resized_crop=125, random=1, face_detection=False, unsharp=1, unsharp_amount=1, unsharp_radius=1, median_hsv=1, median_hsv_method='v', median_hsv_size=3)\n",
    "norm_mean,norm_std=normalize_dataset([train_dataset])\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=0, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, random_resized_crop=125, random=1, unsharp=1, unsharp_amount=1, unsharp_radius=1)\n",
    "test_dataset =  make_dataset('LFW', split='test',  image_size=0, crop=125, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, unsharp=1, unsharp_amount=1, unsharp_radius=1)\n",
    "redefine_train_parameters()\n",
    "name='PA+Unsharp'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')\n",
    "test_dataset = torchvision.datasets.LFWPairs(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.CenterCrop(125),\n",
    "        UnsharpFilter(radius=1,amount=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean,norm_std)\n",
    "    ])\n",
    ")\n",
    "labels,sim_scores = evaluate(model,test_dataset)\n",
    "visualize(labels,sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c3d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "==> Computing mean and std..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9525/9525 [04:32<00:00, 34.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4616, 0.3910, 0.3397]) tensor([0.2253, 0.2041, 0.1949])\n",
      "time elapsed:  272.31480956077576\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=0, random_resized_crop=125, random=1, face_detection=False)\n",
    "norm_mean,norm_std=normalize_dataset([train_dataset])\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=0, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, random_resized_crop=125, random=1)\n",
    "test_dataset =  make_dataset('LFW', split='test',  image_size=0, crop=125, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std)\n",
    "redefine_train_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866d618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00427699089050293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Epoch [1/20]",
       "rate": null,
       "total": 75,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e832a51ac9404985d090dd3ff0627f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [1/20]:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0059337615966796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Epoch [2/20]",
       "rate": null,
       "total": 75,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684403f61fed4ddc972cd43e9de9c880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [2/20]:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_81225/1815533166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mredefine_train_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PA+Crop(100)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'./saved_models/{name}.ptm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mevaluate_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mevaluate_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_81225/3481906671.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, test_dataset, verbose, pretrained, save_path, model_name, optimizer, loss_func_name, use_loss_optimizer, drop_last)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     model = train_model(model_name=model_name,\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mloss_func_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/Experiments/Clean/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, loss_func_name, num_classes, epochs, dataloader, optimizer, use_loss_optimizer, embedding_size, pretrained, learning_rate, loss_learning_rate, margin, alpha, step_size, gamma, momentum, weight_decay, save_path, verbose)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mbatch_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch [{epoch+1}/{epochs}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/datasets/lfw.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0midentity\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/datasets/lfw.py\u001b[0m in \u001b[0;36m_loader\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \"\"\"\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 decoder = Image._getdecoder(\n\u001b[0m\u001b[1;32m    238\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoderconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getdecoder\u001b[0;34m(mode, decoder_name, args, extra)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"decoder {decoder_name} not available\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=0, face_detection=False, random_resized_crop=100, random=1)\n",
    "# norm_mean,norm_std=normalize_dataset([train_dataset])\n",
    "norm_mean,norm_std=torch.tensor([0.4659, 0.3943, 0.3430]),torch.tensor([0.2248, 0.2036, 0.1948])\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=0, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std, random_resized_crop=100, random=1)\n",
    "test_dataset =  make_dataset('LFW', split='test',  image_size=0, crop=100, face_detection=False, normalize=1, norm_mean=norm_mean,norm_std=norm_std)\n",
    "redefine_train_parameters()\n",
    "name='PA+Crop(100)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "evaluate_cos(model,train_loader)\n",
    "evaluate_cos(model,test_loader)\n",
    "test_dataset = torchvision.datasets.LFWPairs(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.CenterCrop(100),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean,norm_std)\n",
    "    ])\n",
    ")\n",
    "labels,sim_scores = evaluate(model,test_dataset)\n",
    "visualize(labels,sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52225264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 75/75 [04:03<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 12.567\n",
      "R@2 : 16.703\n",
      "R@4 : 21.144\n",
      "R@8 : 26.215\n",
      "R@16 : 31.297\n",
      "R@32 : 36.724\n",
      "Average Recall train_PA:\n",
      "R@1 : 0.12566929133858268\n",
      "R@2 : 0.16703412073490814\n",
      "R@4 : 0.21144356955380578\n",
      "R@8 : 0.2621522309711286\n",
      "R@16 : 0.31296587926509184\n",
      "R@32 : 0.36724409448818895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 29/29 [00:55<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 14.132\n",
      "R@2 : 19.606\n",
      "R@4 : 26.160\n",
      "R@8 : 32.497\n",
      "R@16 : 38.916\n",
      "R@32 : 45.146\n",
      "Average Recall test_PA:\n",
      "R@1 : 0.1413160733549083\n",
      "R@2 : 0.19606256742179073\n",
      "R@4 : 0.261596548004315\n",
      "R@8 : 0.3249730312837109\n",
      "R@16 : 0.38915857605177995\n",
      "R@32 : 0.45145631067961167\n"
     ]
    }
   ],
   "source": [
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d43a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAR@FAR:\n",
      "    1%: 0.7240\n",
      "  0.1%: 0.2980\n",
      " 0.01%: 0.1480\n",
      "0.001%: 0.1480\n",
      "Accuracy: 0.819, Threshold: 0.7520571947097778\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.LFWPairs(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.CenterCrop(125),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean,norm_std)\n",
    "    ])\n",
    ")\n",
    "labels,sim_scores = evaluate(model,test_dataset)\n",
    "visualize(labels,sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e908a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, random=True)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False, crop=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf31bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [00:36<00:00, 16.44it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.61it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.57it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:36<00:00, 16.48it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:36<00:00, 16.48it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.57it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.68it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:36<00:00, 16.44it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.66it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:36<00:00, 16.50it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.58it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.57it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.58it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.66it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.65it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.65it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.63it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.59it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.62it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [00:35<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 719.0705 Best loss: 6.4548\n"
     ]
    }
   ],
   "source": [
    "name='PA+Crop(125)+Random'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fff65117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [00:09<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 66.562\n",
      "R@2 : 66.919\n",
      "R@4 : 67.171\n",
      "R@8 : 67.402\n",
      "R@16 : 67.570\n",
      "R@32 : 67.769\n",
      "Average Recall train_PA+Crop(125)+Random:\n",
      "R@1 : 0.6656167979002625\n",
      "R@2 : 0.6691863517060368\n",
      "R@4 : 0.6717060367454069\n",
      "R@8 : 0.6740157480314961\n",
      "R@16 : 0.6756955380577427\n",
      "R@32 : 0.6776902887139108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:03<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 24.784\n",
      "R@2 : 28.937\n",
      "R@4 : 32.362\n",
      "R@8 : 36.300\n",
      "R@16 : 40.022\n",
      "R@32 : 43.770\n",
      "Average Recall test_PA+Crop(125)+Random:\n",
      "R@1 : 0.24784250269687164\n",
      "R@2 : 0.28937432578209277\n",
      "R@4 : 0.32362459546925565\n",
      "R@8 : 0.3629989212513484\n",
      "R@16 : 0.4002157497303128\n",
      "R@32 : 0.4377022653721683\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125)\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b480b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [01:35<00:00,  6.25it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:35<00:00,  6.26it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.29it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.31it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:33<00:00,  6.35it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:33<00:00,  6.34it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.32it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.31it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.32it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.30it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.30it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:34<00:00,  6.29it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:35<00:00,  6.26it/s]\n",
      " 61%|████████████████████████▉                | 362/596 [00:57<00:37,  6.28it/s]"
     ]
    }
   ],
   "source": [
    "for radius,amount in [(1,1),(1,2),(1,3),(3,1),(3,2),(3,3),(5,1),(5,2),(7,1),(7,2),(10,1),(20,1)]:\n",
    "    train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,unsharp_radius=radius,unsharp_amount=amount)\n",
    "    redefine_train_parameters()\n",
    "    train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, random=True, unsharp=1,unsharp_radius=radius,unsharp_amount=amount)\n",
    "    train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "    test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False, crop=125, unsharp=1,unsharp_radius=radius,unsharp_amount=amount)\n",
    "    name=f'PA+Crop(125)+Random+Unsharp(radius={radius},amount={amount})'\n",
    "    model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "    train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,unsharp_radius=radius,unsharp_amount=amount)\n",
    "    train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "    save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "    r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "    avg_recall(f'train_{name}')\n",
    "    save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "    r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "    avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d02b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.00it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.00it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.01it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.02it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:28<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 2970.3397 Best loss: 6.4474\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [01:05<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 68.178\n",
      "R@2 : 68.367\n",
      "R@4 : 68.588\n",
      "R@8 : 68.745\n",
      "R@16 : 68.861\n",
      "R@32 : 68.966\n",
      "Average Recall train_PA+Crop(125)+Random+Unsharp(radius=1,amount=1)+MedianHSV(method=v,size=1):\n",
      "R@1 : 0.6817847769028872\n",
      "R@2 : 0.6836745406824147\n",
      "R@4 : 0.6858792650918635\n",
      "R@8 : 0.6874540682414698\n",
      "R@16 : 0.6886089238845144\n",
      "R@32 : 0.6896587926509187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:25<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 27.913\n",
      "R@2 : 31.769\n",
      "R@4 : 35.275\n",
      "R@8 : 38.808\n",
      "R@16 : 41.775\n",
      "R@32 : 44.930\n",
      "Average Recall test_PA+Crop(125)+Random+Unsharp(radius=1,amount=1)+MedianHSV(method=v,size=1):\n",
      "R@1 : 0.279126213592233\n",
      "R@2 : 0.31769147788565266\n",
      "R@4 : 0.35275080906148865\n",
      "R@8 : 0.38807982740021574\n",
      "R@16 : 0.41774541531823084\n",
      "R@32 : 0.44929881337648325\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [02:46<00:00,  3.59it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:46<00:00,  3.59it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [02:45<00:00,  3.59it/s]\n",
      " 29%|███████████▊                             | 172/596 [00:48<01:57,  3.62it/s]"
     ]
    }
   ],
   "source": [
    "for size in [1,3,5,7,9]:\n",
    "    train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,unsharp_radius=1,unsharp_amount=1,median_hsv=1,median_hsv_method='v',median_hsv_size=size)\n",
    "    redefine_train_parameters()\n",
    "    train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, random=True, unsharp=1,unsharp_radius=1,unsharp_amount=1,median_hsv=1,median_hsv_method='v',median_hsv_size=size)\n",
    "    train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "    test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False, crop=125, unsharp=1,unsharp_radius=1,unsharp_amount=1,median_hsv=1,median_hsv_method='v',median_hsv_size=size)\n",
    "    name=f'PA+Crop(125)+Random+Unsharp(radius=1,amount=1)+MedianHSV(method=v,size={size})'\n",
    "    model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "    train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,unsharp_radius=1,unsharp_amount=1,median_hsv=1,median_hsv_method='v',median_hsv_size=size)\n",
    "    train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "    save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "    r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "    avg_recall(f'train_{name}')\n",
    "    save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "    r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "    avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▊                                | 128/596 [02:17<08:21,  1.07s/it]"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=1,unsharp=1,unsharp_radius=1,unsharp_amount=1)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=1, random=True, unsharp=1,unsharp_radius=1,unsharp_amount=1)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=1, unsharp=1,unsharp_radius=1,unsharp_amount=1)\n",
    "name=f'PA+FaceDetection+Random+Unsharp(radius=1,amount=1)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=100, mtcnn=1,unsharp=1,unsharp_radius=1,unsharp_amount=1)\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a2bd098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,autocontrast=1)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, random=True,autocontrast=1)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False, crop=125, unsharp=1,autocontrast=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1009372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.19it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.24it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.24it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.25it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.26it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.25it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.24it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:21<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:21<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:21<00:00,  7.28it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:21<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.27it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.24it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.26it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.26it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.26it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.25it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [01:22<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 1643.3649 Best loss: 6.4609\n"
     ]
    }
   ],
   "source": [
    "name='PA+Crop(125)+Random+AutoContrast+Unsharp(radius=20,amount=1)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "413f8ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [00:52<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 66.730\n",
      "R@2 : 67.349\n",
      "R@4 : 67.675\n",
      "R@8 : 67.811\n",
      "R@16 : 68.094\n",
      "R@32 : 68.430\n",
      "Average Recall train_PA+Crop(125)+Random+AutoContrast+Unsharp(radius=20,amount=1):\n",
      "R@1 : 0.6672965879265091\n",
      "R@2 : 0.673490813648294\n",
      "R@4 : 0.676745406824147\n",
      "R@8 : 0.6781102362204724\n",
      "R@16 : 0.6809448818897638\n",
      "R@32 : 0.6843044619422572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:20<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 24.784\n",
      "R@2 : 28.344\n",
      "R@4 : 31.769\n",
      "R@8 : 35.059\n",
      "R@16 : 38.835\n",
      "R@32 : 42.665\n",
      "Average Recall test_PA+Crop(125)+Random+AutoContrast+Unsharp(radius=20,amount=1):\n",
      "R@1 : 0.24784250269687164\n",
      "R@2 : 0.2834412081984897\n",
      "R@4 : 0.31769147788565266\n",
      "R@8 : 0.3505933117583603\n",
      "R@16 : 0.3883495145631068\n",
      "R@32 : 0.4266450916936354\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125,unsharp=1,autocontrast=1)\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5fc31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False)\n",
    "test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False)\n",
    "redefine_train_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ae26f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 23.70it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 24.02it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 23.43it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.52it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 22.24it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.60it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 22.13it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.88it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.61it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.82it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 22.45it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.72it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.83it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.99it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.97it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 23.92it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 24.25it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:12<00:00, 23.63it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 22.09it/s]\n",
      "100%|█████████████████████████████████████████| 297/297 [00:13<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 264.7282 Best loss: nan\n"
     ]
    }
   ],
   "source": [
    "name='PFE'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm', optimizer='sgd', model_name='pfe', loss_func_name='mutual_likelihood_score', drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcaf7e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [00:10<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 7.092\n",
      "R@2 : 9.954\n",
      "R@4 : 13.794\n",
      "R@8 : 18.224\n",
      "R@16 : 22.980\n",
      "R@32 : 27.946\n",
      "Average Recall train_PFE:\n",
      "R@1 : 0.07091750841750842\n",
      "R@2 : 0.09953703703703703\n",
      "R@4 : 0.1379419191919192\n",
      "R@8 : 0.18223905723905723\n",
      "R@16 : 0.2297979797979798\n",
      "R@32 : 0.27946127946127947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 115/115 [00:04<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 8.016\n",
      "R@2 : 11.060\n",
      "R@4 : 14.864\n",
      "R@8 : 19.321\n",
      "R@16 : 24.701\n",
      "R@32 : 30.978\n",
      "Average Recall test_PFE:\n",
      "R@1 : 0.08016304347826086\n",
      "R@2 : 0.11059782608695652\n",
      "R@4 : 0.14864130434782608\n",
      "R@8 : 0.19320652173913044\n",
      "R@16 : 0.2470108695652174\n",
      "R@32 : 0.30978260869565216\n"
     ]
    }
   ],
   "source": [
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "708ca4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, random=True)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset = make_dataset('LFW', split='test', image_size=100, face_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed907cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 595/595 [00:39<00:00, 14.88it/s]\n",
      "100%|█████████████████████████████████████████| 595/595 [00:40<00:00, 14.68it/s]\n",
      " 66%|███████████████████████████▏             | 394/595 [00:26<00:13, 14.94it/s]"
     ]
    }
   ],
   "source": [
    "name='PFE+Random'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset,save_path=f'./saved_models/{name}.ptm', optimizer='sgd', model_name='pfe', loss_func_name='mutual_likelihood_score', drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99260c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Average Recall train_PFE+Random:\n",
      "R@1 : 0.07338582677165355\n",
      "R@2 : 0.10656167979002625\n",
      "R@4 : 0.14761154855643044\n",
      "R@8 : 0.19034120734908136\n",
      "R@16 : 0.23748031496062993\n",
      "R@32 : 0.29039370078740157\n",
      "Average Recall test_PFE+Random:\n",
      "R@1 : 0.08396739130434783\n",
      "R@2 : 0.11875\n",
      "R@4 : 0.15815217391304348\n",
      "R@8 : 0.2\n",
      "R@16 : 0.25516304347826085\n",
      "R@32 : 0.3095108695652174\n"
     ]
    }
   ],
   "source": [
    "name='PFE+Random'\n",
    "model = torch.load(f'./saved_models/{name}.ptm')\n",
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False)\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = load_dataset(test_dataset, batch_size=32, shuffle=False)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944c4c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3, random=True)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset  = make_dataset('LFW', split='test',  image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc58cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [03:31<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:30<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:32<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:32<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:33<00:00,  2.80it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:30<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:31<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:30<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:29<00:00,  2.85it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:31<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:29<00:00,  2.85it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:28<00:00,  2.85it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:30<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:31<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:28<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:35<00:00,  2.77it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:34<00:00,  2.78it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:33<00:00,  2.79it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:34<00:00,  2.78it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [03:33<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 4231.4121 Best loss: 6.4288\n"
     ]
    }
   ],
   "source": [
    "name='PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset, save_path=f'./saved_models/{name}.ptm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58f59f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [01:35<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 69.543\n",
      "R@2 : 69.711\n",
      "R@4 : 69.774\n",
      "R@8 : 69.827\n",
      "R@16 : 69.858\n",
      "R@32 : 69.869\n",
      "Average Recall train_PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.6954330708661417\n",
      "R@2 : 0.6971128608923884\n",
      "R@4 : 0.697742782152231\n",
      "R@8 : 0.6982677165354331\n",
      "R@16 : 0.6985826771653544\n",
      "R@32 : 0.6986876640419948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:37<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 24.838\n",
      "R@2 : 27.859\n",
      "R@4 : 31.203\n",
      "R@8 : 34.466\n",
      "R@16 : 38.457\n",
      "R@32 : 42.530\n",
      "Average Recall test_PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.2483818770226537\n",
      "R@2 : 0.2785868392664509\n",
      "R@4 : 0.31202804746494067\n",
      "R@8 : 0.3446601941747573\n",
      "R@16 : 0.38457389428263217\n",
      "R@32 : 0.42529665587918014\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "name='PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3)'\n",
    "model = torch.load(f'./saved_models/{name}.ptm')\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = load_dataset(test_dataset, batch_size=32, shuffle=False)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efe48eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=5, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3, random=True)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=5, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset  = make_dataset('LFW', split='test',  image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=5, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3533bd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 596/596 [04:31<00:00,  2.19it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:31<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:31<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:29<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n",
      "100%|█████████████████████████████████████████| 596/596 [04:30<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training, Time: 5413.2616 Best loss: 6.4355\n"
     ]
    }
   ],
   "source": [
    "name='PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=5,amount=1)+MedianHSV(method=sv,size=3)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset, save_path=f'./saved_models/{name}.ptm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "903fc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 298/298 [02:07<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 69.081\n",
      "R@2 : 69.239\n",
      "R@4 : 69.396\n",
      "R@8 : 69.512\n",
      "R@16 : 69.638\n",
      "R@32 : 69.743\n",
      "Average Recall train_PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=5,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.6908136482939633\n",
      "R@2 : 0.6923884514435695\n",
      "R@4 : 0.6939632545931759\n",
      "R@8 : 0.6951181102362205\n",
      "R@16 : 0.6963779527559055\n",
      "R@32 : 0.6974278215223098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:49<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R@1 : 25.755\n",
      "R@2 : 29.234\n",
      "R@4 : 32.524\n",
      "R@8 : 36.003\n",
      "R@16 : 39.725\n",
      "R@32 : 43.042\n",
      "Average Recall test_PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=5,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.2575512405609493\n",
      "R@2 : 0.2923408845738943\n",
      "R@4 : 0.32524271844660196\n",
      "R@8 : 0.36003236245954695\n",
      "R@16 : 0.39724919093851135\n",
      "R@32 : 0.43042071197411\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=5, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "name='PA+Crop(125)+Random+AutoContrast+MedianUnsharp(size=5,amount=1)+MedianHSV(method=sv,size=3)'\n",
    "model = torch.load(f'./saved_models/{name}.ptm')\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = load_dataset(test_dataset, batch_size=32, shuffle=False)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b63887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3, random=True)\n",
    "redefine_train_parameters()\n",
    "train_dataset2 = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset,train_dataset2])\n",
    "test_dataset  = make_dataset('LFW', split='test',  image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6852583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 595/595 [03:18<00:00,  3.00it/s]\n",
      " 82%|█████████████████████████████████▍       | 486/595 [02:40<00:35,  3.07it/s]"
     ]
    }
   ],
   "source": [
    "name='PFE+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3)'\n",
    "model, train_loader, test_loader = train(train_dataset,test_dataset, save_path=f'./saved_models/{name}.ptm', model_name='pfe', optimizer='sgd', loss_func_name='mutual_likelihood_score', drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbbdea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Average Recall train_PFE+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.08220472440944881\n",
      "R@2 : 0.11559055118110237\n",
      "R@4 : 0.15391076115485564\n",
      "R@8 : 0.19380577427821521\n",
      "R@16 : 0.2388451443569554\n",
      "R@32 : 0.2895538057742782\n",
      "Average Recall test_PFE+Crop(125)+Random+AutoContrast+MedianUnsharp(size=1,amount=1)+MedianHSV(method=sv,size=3):\n",
      "R@1 : 0.08695652173913043\n",
      "R@2 : 0.11847826086956521\n",
      "R@4 : 0.15054347826086956\n",
      "R@8 : 0.19782608695652174\n",
      "R@16 : 0.25570652173913044\n",
      "R@32 : 0.31222826086956523\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset('LFW', split='train', image_size=100, face_detection=False, crop=125, autocontrast=True, median_unsharp=True, median_unsharp_size=1, median_unsharp_amount=1, median_hsv=True, median_hsv_method='sv', median_hsv_size=3)\n",
    "train_loader = load_dataset(train_dataset, batch_size=32, shuffle=True)\n",
    "save_output(evaluate_cos(model,train_loader),f'train_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'train_{name}']\n",
    "avg_recall(f'train_{name}')\n",
    "save_output(evaluate_cos(model,test_loader),f'test_{name}')\n",
    "r1,r2,r4,r8,r16,r32=load_output()[f'test_{name}']\n",
    "avg_recall(f'test_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbfddf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = then-time.time()\n",
    "save_output(total_time, 'total_time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
